{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Ensemble(Ensemble)  (VGG16+ResNet50) x (effecientnet+VGG19) experiment ",
      "provenance": [],
      "collapsed_sections": [
        "yqqCqrBJm_Ko",
        "p7leDEQAQDpu",
        "wzZMhQhPaFm5",
        "qHQ7hr08asYg",
        "8HbMxq84bWas",
        "9vHr4hLG0BBU"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vallimeenaa9/Breast_Cancer/blob/main/Ensemble(Ensemble)_(VGG16%2BResNet50)_x_(effecientnet%2BVGG19)_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqqCqrBJm_Ko"
      },
      "source": [
        "# Data loading and preprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1204WbKCRvU3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFWhwrERZEYw"
      },
      "source": [
        "pip install torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVk-2tOmQOzz"
      },
      "source": [
        "!pip install -U efficientnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxu3l09rZcLI"
      },
      "source": [
        "import efficientnet.keras as efn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtYuBeRxSRAh"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/Cancer_PNG.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycGN6B6Sc_JY"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from keras.models import Sequential,Model\n",
        "from keras.applications.vgg16 import preprocess_input,VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.layers import MaxPooling2D,Conv2D,Dense,BatchNormalization,Dropout,GlobalAveragePooling2D,Flatten,Input,GlobalMaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import ipywidgets as widgets\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import io\n",
        "from PIL import Image\n",
        "from IPython.display import display,clear_output\n",
        "from warnings import filterwarnings\n",
        "from glob import glob\n",
        "from tifffile import imread, imwrite\n",
        "from skimage.transform import resize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHE1jl5qdH2U"
      },
      "source": [
        "len(os.listdir('/tmp/Cancer_PNG/'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBtKy28ddo-W"
      },
      "source": [
        "# Prepere data\n",
        "benign = os.listdir('/tmp/Cancer_PNG/Benign')\n",
        "insitu  = os.listdir('/tmp/Cancer_PNG/InSitu')\n",
        "invasive  = os.listdir('/tmp/Cancer_PNG/Invasive')\n",
        "normal  = os.listdir('/tmp/Cancer_PNG/Normal')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIz1bawHetcg"
      },
      "source": [
        "# Prepere input data\n",
        "X_data =[]\n",
        "for file in benign:\n",
        "    img = cv2.imread('/tmp/Cancer_PNG/Benign/'+file)\n",
        "    face = cv2.resize(img, (224, 224) )\n",
        "    (b, g, r)=cv2.split(face) \n",
        "    img=cv2.merge([r,g,b])\n",
        "    X_data.append(img)\n",
        "\n",
        "for file in insitu:\n",
        "    img = cv2.imread('/tmp/Cancer_PNG/InSitu/'+file)\n",
        "    face = cv2.resize(img, (224, 224) )\n",
        "    (b, g, r)=cv2.split(face) \n",
        "    img=cv2.merge([r,g,b])\n",
        "    X_data.append(img)\n",
        "  \n",
        "for file in invasive:\n",
        "    img = cv2.imread('/tmp/Cancer_PNG/Invasive/'+file)\n",
        "    face = cv2.resize(img, (224, 224) )\n",
        "    (b, g, r)=cv2.split(face) \n",
        "    img=cv2.merge([r,g,b])\n",
        "    X_data.append(img)\n",
        "\n",
        "for file in normal:\n",
        "    img = cv2.imread('/tmp/Cancer_PNG/Normal/'+file)\n",
        "    face = cv2.resize(img, (224, 224) )\n",
        "    (b, g, r)=cv2.split(face) \n",
        "    img=cv2.merge([r,g,b])\n",
        "    X_data.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAViaTLv0Z8A"
      },
      "source": [
        "image_width=224\n",
        "image_height=224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sscv4r0j1zK"
      },
      "source": [
        "X = np.squeeze(X_data)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzRYBodLj6aJ"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(X[5], interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oOKDsV2k6to"
      },
      "source": [
        "target_benign=np.full(len(benign),3)\n",
        "target_insitu=np.full(len(insitu),2)\n",
        "target_invasive=np.full(len(invasive),1)\n",
        "target_normal=np.full(len(normal),0)\n",
        "Y=np.concatenate([target_benign,target_insitu,target_invasive,target_normal])\n",
        "Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-gjJteImezQ"
      },
      "source": [
        "len(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD5xIKa3mh6T"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle='true')\n",
        "number_of_train = X_train.shape[0]\n",
        "number_of_test = X_test.shape[0]\n",
        "print('number_of_train:', number_of_train)\n",
        "print('number_of_test:', number_of_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYTyBVUmy0xe"
      },
      "source": [
        "# Ensemble(Ensemble)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7leDEQAQDpu"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmIU5dlEQFll"
      },
      "source": [
        "early_stop=EarlyStopping(patience=4)\n",
        "reduceLR=ReduceLROnPlateau(patience=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-StCYI-URTBv"
      },
      "source": [
        "# detect and init the TPU\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "# instantiate a distribution strategy\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExdbNJw0QLD8"
      },
      "source": [
        "  with tpu_strategy.scope():\n",
        "      vgg_model = VGG16(weights='imagenet',include_top=False)\n",
        "      for layers in vgg_model.layers:\n",
        "          layers.trainable=False\n",
        "      x=vgg_model.output\n",
        "      x=GlobalAveragePooling2D()(x)\n",
        "      x=Dense(128,activation='relu')(x)\n",
        "      x=Dropout(0.15)(x)\n",
        "      output=Dense(4,activation='softmax')(x)\n",
        "      model2=Model(inputs=vgg_model.input,outputs=output)\n",
        "      model2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r2s6L6tQR_B"
      },
      "source": [
        "from random import shuffle\n",
        "\n",
        "ind_list = [i for i in range(len(X_train))]\n",
        "shuffle(ind_list)\n",
        "X_train_new  = X_train[ind_list, :,:,:]\n",
        "Y_train_new = Y_train[ind_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUXsTXpbh9Kj"
      },
      "source": [
        "# Checkpoint to save best model per epoch\n",
        "model_filepath = \"/content/drive/My Drive/vgg-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
        "model_checkpoint_callbackvgg = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_filepath,\n",
        "    verbose=1,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8zrV0EdQtbA"
      },
      "source": [
        "r2=model2.fit(X_train_new,Y_train_new,validation_split=0.2,epochs=20, callbacks=[model_checkpoint_callbackvgg])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzZMhQhPaFm5"
      },
      "source": [
        "## ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpgVXl8VTJ7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa2a3b0-429b-45bb-f869-ef944b922a2a"
      },
      "source": [
        "with tpu_strategy.scope():\n",
        "  res=tf.keras.applications.ResNet50(weights='imagenet',include_top=False)\n",
        "  for layers in res.layers:\n",
        "          layers.trainable=False\n",
        "  x=res.output\n",
        "  x=GlobalAveragePooling2D()(x)\n",
        "  x=Dense(128,activation='relu')(x)\n",
        "  x=Dropout(0.15)(x)\n",
        "  output=Dense(4,activation='softmax')(x)\n",
        "  model3=Model(inputs=res.input,outputs=output)\n",
        "  model3.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5oMdKoxU6q8"
      },
      "source": [
        "from random import shuffle\n",
        "\n",
        "ind_list = [i for i in range(len(X_train))]\n",
        "shuffle(ind_list)\n",
        "X_train_new  = X_train[ind_list, :,:,:]\n",
        "Y_train_new = Y_train[ind_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3IVnDe_jMSM"
      },
      "source": [
        "model_filepath = \"/content/drive/My Drive/res-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
        "model_checkpoint_callbackres = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_filepath,\n",
        "    verbose=1,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fi46ZngVB4o",
        "outputId": "cc22b632-7833-48c2-afa9-c6e88f0547a8"
      },
      "source": [
        "r2=model3.fit(X_train_new,Y_train_new,validation_split=0.2,epochs=20, callbacks=[model_checkpoint_callbackres])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 58s 4s/step - loss: 1.6236 - accuracy: 0.3906 - val_loss: 0.9484 - val_accuracy: 0.5938\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.59375, saving model to /content/drive/My Drive/res-01-0.5938.hdf5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 0.8432 - accuracy: 0.6836 - val_loss: 0.7423 - val_accuracy: 0.6719\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.59375 to 0.67188, saving model to /content/drive/My Drive/res-02-0.6719.hdf5\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 0.6755 - accuracy: 0.7617 - val_loss: 0.5621 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.67188 to 0.75000, saving model to /content/drive/My Drive/res-03-0.7500.hdf5\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 1s 147ms/step - loss: 0.5295 - accuracy: 0.8242 - val_loss: 0.6469 - val_accuracy: 0.7344\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.75000\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 1s 129ms/step - loss: 0.4677 - accuracy: 0.8281 - val_loss: 0.5372 - val_accuracy: 0.7969\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.75000 to 0.79688, saving model to /content/drive/My Drive/res-05-0.7969.hdf5\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 1s 172ms/step - loss: 0.3924 - accuracy: 0.8516 - val_loss: 0.6206 - val_accuracy: 0.7188\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.79688\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.3449 - accuracy: 0.8750 - val_loss: 0.5145 - val_accuracy: 0.7969\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.79688\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.3038 - accuracy: 0.9023 - val_loss: 0.5771 - val_accuracy: 0.7344\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.79688\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 0.2335 - accuracy: 0.9180 - val_loss: 0.4919 - val_accuracy: 0.7812\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.79688\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 1s 120ms/step - loss: 0.1914 - accuracy: 0.9492 - val_loss: 0.5539 - val_accuracy: 0.7656\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.79688\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 1s 129ms/step - loss: 0.1830 - accuracy: 0.9688 - val_loss: 0.4893 - val_accuracy: 0.7812\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.79688\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 1s 168ms/step - loss: 0.1508 - accuracy: 0.9688 - val_loss: 0.5610 - val_accuracy: 0.7344\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.79688\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 0.1418 - accuracy: 0.9805 - val_loss: 0.5287 - val_accuracy: 0.7969\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.79688\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 0.1195 - accuracy: 0.9688 - val_loss: 0.5529 - val_accuracy: 0.7656\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.79688\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 1s 114ms/step - loss: 0.1080 - accuracy: 0.9883 - val_loss: 0.5480 - val_accuracy: 0.7812\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.79688\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 0.0963 - accuracy: 0.9922 - val_loss: 0.5030 - val_accuracy: 0.8125\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.79688 to 0.81250, saving model to /content/drive/My Drive/res-16-0.8125.hdf5\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 0.0901 - accuracy: 0.9883 - val_loss: 0.6039 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.81250\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.5424 - val_accuracy: 0.8125\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.81250\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.5809 - val_accuracy: 0.8125\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.81250\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 0.0569 - accuracy: 0.9961 - val_loss: 0.5440 - val_accuracy: 0.8281\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.81250 to 0.82812, saving model to /content/drive/My Drive/res-20-0.8281.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHQ7hr08asYg"
      },
      "source": [
        "## Ensemble1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYh8nNpAWCJS"
      },
      "source": [
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Average\n",
        "model_1 = load_model(\"/content/drive/My Drive/vgg-13-0.7344.hdf5\")\n",
        "model_1 = Model(inputs=model_1.inputs,\n",
        "                outputs=model_1.outputs,\n",
        "                name='vgg16')\n",
        "model_2 = load_model(\"/content/drive/My Drive/res-20-0.8281.hdf5\")\n",
        "model_2 = Model(inputs=model_2.inputs,\n",
        "                outputs=model_2.outputs,\n",
        "                name='resnet50')\n",
        "models = [model_1, model_2]\n",
        "model_input = Input(shape=(image_width, image_height, 3))\n",
        "model_outputs = [model(model_input) for model in models]\n",
        "ensemble_output = Average()(model_outputs)\n",
        "ensemble_model = Model(inputs=model_input, outputs=ensemble_output, name='ensemble')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjL_4LqYmuZk"
      },
      "source": [
        " ensemble_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBqzpiEEWU6H"
      },
      "source": [
        "model_filepath = \"/content/drive/My Drive/e1-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
        "model_checkpoint_callbacke1 = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_filepath,\n",
        "    verbose=1,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXefgF5jm3RS",
        "outputId": "6f346f50-f530-4239-fafe-9d6ca477cbcf"
      },
      "source": [
        "r4=ensemble_model.fit(X_train_new,Y_train_new,validation_split=0.2,epochs=20, callbacks=[model_checkpoint_callbacke1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 10s 809ms/step - loss: 0.1419 - accuracy: 0.9688 - val_loss: 0.3925 - val_accuracy: 0.8906\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.89062, saving model to /content/drive/My Drive/e1-01-0.8906.hdf5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20\n",
            "8/8 [==============================] - 5s 628ms/step - loss: 0.1391 - accuracy: 0.9531 - val_loss: 0.3121 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.89062\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 5s 644ms/step - loss: 0.0968 - accuracy: 0.9844 - val_loss: 0.3516 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.89062\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 5s 627ms/step - loss: 0.0822 - accuracy: 0.9922 - val_loss: 0.3752 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.89062\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 5s 628ms/step - loss: 0.0657 - accuracy: 0.9961 - val_loss: 0.2986 - val_accuracy: 0.8594\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.89062\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 5s 630ms/step - loss: 0.0590 - accuracy: 0.9883 - val_loss: 0.2711 - val_accuracy: 0.8906\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.89062\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 5s 623ms/step - loss: 0.0488 - accuracy: 0.9961 - val_loss: 0.3112 - val_accuracy: 0.8281\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.89062\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 5s 627ms/step - loss: 0.0513 - accuracy: 0.9922 - val_loss: 0.2669 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.89062\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 5s 628ms/step - loss: 0.0352 - accuracy: 0.9961 - val_loss: 0.3906 - val_accuracy: 0.8438\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.89062\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 5s 627ms/step - loss: 0.0337 - accuracy: 0.9922 - val_loss: 0.3262 - val_accuracy: 0.8438\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.89062\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 5s 672ms/step - loss: 0.0304 - accuracy: 0.9961 - val_loss: 0.3218 - val_accuracy: 0.8438\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.89062\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 5s 633ms/step - loss: 0.0251 - accuracy: 0.9961 - val_loss: 0.2970 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.89062\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 5s 630ms/step - loss: 0.0259 - accuracy: 0.9922 - val_loss: 0.3342 - val_accuracy: 0.8906\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.89062\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 5s 629ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.3969 - val_accuracy: 0.8438\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.89062\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 5s 625ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.89062\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 5s 628ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.4104 - val_accuracy: 0.8438\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.89062\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 5s 625ms/step - loss: 0.0179 - accuracy: 0.9961 - val_loss: 0.3639 - val_accuracy: 0.8594\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.89062\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 5s 625ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.8594\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.89062\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 5s 623ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.8594\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.89062\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 5s 630ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.8594\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.89062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HbMxq84bWas"
      },
      "source": [
        "## EffecientNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Si2OYuXivd"
      },
      "source": [
        "import keras.utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McnN_SY3YUbj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "8aefc414-7b75-47b1-d78a-b8af43195bcc"
      },
      "source": [
        "pip install segmentation-models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation-models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.8)\n",
            "Collecting image-classifiers==1.0.0\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.16.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.5.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.15.0)\n",
            "Installing collected packages: image-classifiers, efficientnet, segmentation-models\n",
            "  Attempting uninstall: efficientnet\n",
            "    Found existing installation: efficientnet 1.1.1\n",
            "    Uninstalling efficientnet-1.1.1:\n",
            "      Successfully uninstalled efficientnet-1.1.1\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 segmentation-models-1.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "efficientnet"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs3rEc-aYJzn",
        "outputId": "b66896ce-b44f-4c5a-97cc-a9860b5d4331"
      },
      "source": [
        "import segmentation_models as sm\n",
        "sm.set_framework('tf.keras')\n",
        "sm.framework()\n",
        "%env SM_FRAMEWORK=tf.keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: SM_FRAMEWORK=tf.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUli_5QTVvYz"
      },
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "with tpu_strategy.scope():\n",
        "  eff = EfficientNetB0(weights='imagenet')\n",
        "  for layers in eff.layers:\n",
        "          layers.trainable=False\n",
        "  x=eff.output\n",
        "  #x=GlobalMaxPooling2D()(x)\n",
        "  x=Dense(128,activation='relu')(x)\n",
        "  x=Dropout(0.15)(x)\n",
        "  output=Dense(4,activation='softmax')(x)\n",
        "  model5=Model(inputs=eff.input,outputs=output)\n",
        "  model5.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        " \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFQ2xvtkXHTy"
      },
      "source": [
        "model_filepath = \"/content/drive/My Drive/ef-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
        "model_checkpoint_callbackef = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_filepath,\n",
        "    verbose=1,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmwdjRXFWryP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4f06c6-9c8c-4005-e982-1fa510cd3d12"
      },
      "source": [
        "\n",
        "r2=model5.fit(X_train_new,Y_train_new,validation_split=0.2,epochs=20, callbacks=[model_checkpoint_callbackef])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 31s 2s/step - loss: 1.3831 - accuracy: 0.3008 - val_loss: 1.3779 - val_accuracy: 0.4844\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.48438, saving model to /content/drive/My Drive/ef-01-0.4844.hdf5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20\n",
            "8/8 [==============================] - 1s 126ms/step - loss: 1.3733 - accuracy: 0.5000 - val_loss: 1.3717 - val_accuracy: 0.4688\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.48438\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 1s 132ms/step - loss: 1.3659 - accuracy: 0.5195 - val_loss: 1.3648 - val_accuracy: 0.4375\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.48438\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 1s 134ms/step - loss: 1.3544 - accuracy: 0.5391 - val_loss: 1.3568 - val_accuracy: 0.4375\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.48438\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.3430 - accuracy: 0.5508 - val_loss: 1.3490 - val_accuracy: 0.4375\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.48438\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 1.3304 - accuracy: 0.5352 - val_loss: 1.3394 - val_accuracy: 0.4219\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.48438\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 1s 139ms/step - loss: 1.3173 - accuracy: 0.5430 - val_loss: 1.3284 - val_accuracy: 0.4531\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.48438\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 1.3018 - accuracy: 0.5625 - val_loss: 1.3163 - val_accuracy: 0.4375\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.48438\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.2800 - accuracy: 0.6094 - val_loss: 1.3051 - val_accuracy: 0.4375\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.48438\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 1s 133ms/step - loss: 1.2733 - accuracy: 0.5430 - val_loss: 1.2934 - val_accuracy: 0.4375\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.48438\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 1s 125ms/step - loss: 1.2452 - accuracy: 0.5938 - val_loss: 1.2781 - val_accuracy: 0.4375\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.48438\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 1s 125ms/step - loss: 1.2299 - accuracy: 0.5938 - val_loss: 1.2569 - val_accuracy: 0.4844\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.48438\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 1.2028 - accuracy: 0.5938 - val_loss: 1.2488 - val_accuracy: 0.4531\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.48438\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 1.1973 - accuracy: 0.5820 - val_loss: 1.2364 - val_accuracy: 0.4688\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.48438\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 1s 130ms/step - loss: 1.1784 - accuracy: 0.5781 - val_loss: 1.2212 - val_accuracy: 0.4844\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.48438\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 1s 128ms/step - loss: 1.1532 - accuracy: 0.6172 - val_loss: 1.2086 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.48438 to 0.50000, saving model to /content/drive/My Drive/ef-16-0.5000.hdf5\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 1.1357 - accuracy: 0.6211 - val_loss: 1.1974 - val_accuracy: 0.5156\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.50000 to 0.51562, saving model to /content/drive/My Drive/ef-17-0.5156.hdf5\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 1s 125ms/step - loss: 1.1032 - accuracy: 0.6367 - val_loss: 1.1857 - val_accuracy: 0.5156\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.51562\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 1s 131ms/step - loss: 1.1084 - accuracy: 0.6211 - val_loss: 1.1678 - val_accuracy: 0.5312\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.51562 to 0.53125, saving model to /content/drive/My Drive/ef-19-0.5312.hdf5\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 1s 138ms/step - loss: 1.0902 - accuracy: 0.6367 - val_loss: 1.1580 - val_accuracy: 0.5312\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.53125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vHr4hLG0BBU"
      },
      "source": [
        "## VGG19\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP35T6nZz--x"
      },
      "source": [
        "with tpu_strategy.scope():\n",
        "      vgg19_model = VGG19(weights='imagenet',include_top=False)\n",
        "      for layers in vgg19_model.layers:\n",
        "          layers.trainable=False\n",
        "      x=vgg19_model.output\n",
        "      x=GlobalAveragePooling2D()(x)\n",
        "      x=Dense(128,activation='relu')(x)\n",
        "      x=Dropout(0.15)(x)\n",
        "      output=Dense(4,activation='softmax')(x)\n",
        "      model2=Model(inputs=vgg19_model.input,outputs=output)\n",
        "      model2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGeDFxvY2TIk"
      },
      "source": [
        "from random import shuffle\n",
        "\n",
        "ind_list = [i for i in range(len(X_train))]\n",
        "shuffle(ind_list)\n",
        "X_train_new  = X_train[ind_list, :,:,:]\n",
        "Y_train_new = Y_train[ind_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv5BcGxI2Wxs"
      },
      "source": [
        "# Checkpoint to save best model per epoch\n",
        "model_filepath = \"/content/drive/My Drive/vgg19-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
        "model_checkpoint_callbackvgg19 = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_filepath,\n",
        "    verbose=1,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K09Tw4dC2bYz",
        "outputId": "dda41303-9960-405b-df7c-ae06d5cf6666"
      },
      "source": [
        "r2=model2.fit(X_train_new,Y_train_new,validation_split=0.2,epochs=20, callbacks=[model_checkpoint_callbackvgg19])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 11s 657ms/step - loss: 2.9319 - accuracy: 0.4219 - val_loss: 1.9797 - val_accuracy: 0.5312\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.53125, saving model to /content/drive/My Drive/vgg19-01-0.5312.hdf5\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 1s 128ms/step - loss: 1.7353 - accuracy: 0.5547 - val_loss: 1.7547 - val_accuracy: 0.6406\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.53125 to 0.64062, saving model to /content/drive/My Drive/vgg19-02-0.6406.hdf5\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 1.3401 - accuracy: 0.6250 - val_loss: 1.5786 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.64062\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 0.9647 - accuracy: 0.7031 - val_loss: 1.3921 - val_accuracy: 0.7031\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.64062 to 0.70312, saving model to /content/drive/My Drive/vgg19-04-0.7031.hdf5\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 1s 126ms/step - loss: 0.6195 - accuracy: 0.7773 - val_loss: 1.2720 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.70312\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 1s 126ms/step - loss: 0.5476 - accuracy: 0.8047 - val_loss: 1.1224 - val_accuracy: 0.7031\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.70312\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 1s 125ms/step - loss: 0.5086 - accuracy: 0.8086 - val_loss: 1.0692 - val_accuracy: 0.7188\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.70312 to 0.71875, saving model to /content/drive/My Drive/vgg19-07-0.7188.hdf5\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 0.4096 - accuracy: 0.8320 - val_loss: 1.1197 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.71875\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 1s 150ms/step - loss: 0.2980 - accuracy: 0.8945 - val_loss: 1.1625 - val_accuracy: 0.7188\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.71875\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 2s 217ms/step - loss: 0.2683 - accuracy: 0.8906 - val_loss: 1.1684 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.71875\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 1s 140ms/step - loss: 0.2637 - accuracy: 0.8984 - val_loss: 1.2033 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.71875\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 1s 201ms/step - loss: 0.1845 - accuracy: 0.9375 - val_loss: 1.2117 - val_accuracy: 0.7188\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.71875\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 1s 136ms/step - loss: 0.1615 - accuracy: 0.9453 - val_loss: 1.2016 - val_accuracy: 0.7031\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.71875\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 1s 125ms/step - loss: 0.1619 - accuracy: 0.9492 - val_loss: 1.3089 - val_accuracy: 0.6406\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.71875\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 0.1136 - accuracy: 0.9570 - val_loss: 1.2833 - val_accuracy: 0.6562\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.71875\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 0.0891 - accuracy: 0.9727 - val_loss: 1.2799 - val_accuracy: 0.6562\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.71875\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 0.1085 - accuracy: 0.9648 - val_loss: 1.2348 - val_accuracy: 0.6719\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.71875\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 0.1015 - accuracy: 0.9688 - val_loss: 1.2453 - val_accuracy: 0.6406\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.71875\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 1s 126ms/step - loss: 0.0900 - accuracy: 0.9766 - val_loss: 1.2786 - val_accuracy: 0.6406\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.71875\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 1s 128ms/step - loss: 0.0972 - accuracy: 0.9688 - val_loss: 1.3021 - val_accuracy: 0.6094\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.71875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLON3tGz2xAq"
      },
      "source": [
        "## Ensemble2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YAQObyO20CI"
      },
      "source": [
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Average\n",
        "model_1 = load_model(\"/content/drive/My Drive/e1-01-0.8906.hdf5\")\n",
        "model_1 = Model(inputs=model_1.inputs,\n",
        "                outputs=model_1.outputs,\n",
        "                name='e1')\n",
        "model_2 = load_model(\"/content/drive/My Drive/vgg19-07-0.7188.hdf5\")\n",
        "model_2 = Model(inputs=model_2.inputs,\n",
        "                outputs=model_2.outputs,\n",
        "                name='vgg19')\n",
        "models = [model_1, model_2]\n",
        "model_input = Input(shape=(image_width, image_height, 3))\n",
        "model_outputs = [model(model_input) for model in models]\n",
        "ensemble2_output = Average()(model_outputs)\n",
        "ensemble2_model = Model(inputs=model_input, outputs=ensemble2_output, name='ensemble')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpj2fOkl2632"
      },
      "source": [
        "ensemble2_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CQrBNTu2-OK"
      },
      "source": [
        "model_filepath = \"/content/drive/My Drive/e2-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
        "model_checkpoint_callbacke2 = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_filepath,\n",
        "    verbose=1,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvsq3C2E3BXX",
        "outputId": "c85c6304-b684-4f73-ec7c-640c0f53a317"
      },
      "source": [
        "r4=ensemble2_model.fit(X_train_new,Y_train_new,validation_split=0.2,epochs=20, callbacks=[model_checkpoint_callbacke2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.0295 - accuracy: 0.9961 - val_loss: 0.5457 - val_accuracy: 0.7188\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.82812\n",
            "Epoch 2/20\n"
          ]
        }
      ]
    }
  ]
}