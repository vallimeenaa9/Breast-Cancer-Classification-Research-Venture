{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cancer Image Classification on BACH Dataset using Ensemble Learning - Research Venture",
      "provenance": [],
      "authorship_tag": "ABX9TyOK7LF9BXCrDtJkSTj4DKe5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vallimeenaa9/Breast_Cancer/blob/main/Cancer_Image_Classification_on_BACH_Dataset_using_Ensemble_Learning_Research_Venture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGNlfNNK7Aht"
      },
      "source": [
        "##**Joint Research venture between V Valli Meenaa, Aadhi Aadhavan, and Dr. V. Jitendra Tembhurne (IIIT-N)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkwXvrHS7rKW"
      },
      "source": [
        "###Loading Data, Data Pre-Processing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdDCtH4p5AaL"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2OQA1Mr5MCe"
      },
      "source": [
        "pip install torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r8Pc6R_5NGi"
      },
      "source": [
        "!pip install -U efficientnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZF1MH_Z5T9N"
      },
      "source": [
        "import efficientnet.keras as efn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McfcTGbS5aZC"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/Cancer_PNG.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJbClb3T5g74"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from keras.models import Sequential,Model\n",
        "from keras.applications.vgg16 import preprocess_input,VGG16\n",
        "from keras.layers import MaxPooling2D,Conv2D,Dense,BatchNormalization,Dropout,GlobalAveragePooling2D,Flatten,Input,GlobalMaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import ipywidgets as widgets\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import io\n",
        "from PIL import Image\n",
        "from IPython.display import display,clear_output\n",
        "from warnings import filterwarnings\n",
        "from glob import glob\n",
        "from tifffile import imread, imwrite\n",
        "from skimage.transform import resize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRT8Zhee5kvi"
      },
      "source": [
        "len(os.listdir('/tmp/Cancer_PNG/'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4qsrN-m5m7r"
      },
      "source": [
        "# Prepere data\n",
        "benign = os.listdir('/tmp/Cancer_PNG/Benign')\n",
        "insitu  = os.listdir('/tmp/Cancer_PNG/InSitu')\n",
        "invasive  = os.listdir('/tmp/Cancer_PNG/Invasive')\n",
        "normal  = os.listdir('/tmp/Cancer_PNG/Normal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeqUaWcQ5t6B"
      },
      "source": [
        "# Prepere input data\n",
        "X_data =[]\n",
        "for file in benign:\n",
        "    img = cv2.imread('/tmp/Cancer_PNG/Benign/'+file)\n",
        "    face = cv2.resize(img, (224, 224) )\n",
        "    (b, g, r)=cv2.split(face) \n",
        "    img=cv2.merge([r,g,b])\n",
        "    X_data.append(img)\n",
        "\n",
        "for file in insitu:\n",
        "    img = cv2.imread('/tmp/Cancer_PNG/InSitu/'+file)\n",
        "    face = cv2.resize(img, (224, 224) )\n",
        "    (b, g, r)=cv2.split(face) \n",
        "    img=cv2.merge([r,g,b])\n",
        "    X_data.append(img)\n",
        "  \n",
        "for file in invasive:\n",
        "    img = cv2.imread('/tmp/Cancer_PNG/Invasive/'+file)\n",
        "    face = cv2.resize(img, (224, 224) )\n",
        "    (b, g, r)=cv2.split(face) \n",
        "    img=cv2.merge([r,g,b])\n",
        "    X_data.append(img)\n",
        "\n",
        "for file in normal:\n",
        "    img = cv2.imread('/tmp/Cancer_PNG/Normal/'+file)\n",
        "    face = cv2.resize(img, (224, 224) )\n",
        "    (b, g, r)=cv2.split(face) \n",
        "    img=cv2.merge([r,g,b])\n",
        "    X_data.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2cwZJAO6F1E"
      },
      "source": [
        "image_width=224\n",
        "image_height=224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqW-5Ep56IOU"
      },
      "source": [
        "X = np.squeeze(X_data)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIgz9LN26Km_"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(X[5], interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x09ohyB06ODq"
      },
      "source": [
        "target_benign=np.full(len(benign),3)\n",
        "target_insitu=np.full(len(insitu),2)\n",
        "target_invasive=np.full(len(invasive),1)\n",
        "target_normal=np.full(len(normal),0)\n",
        "Y=np.concatenate([target_benign,target_insitu,target_invasive,target_normal])\n",
        "Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cceAS9mp6Yr_"
      },
      "source": [
        "len(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iTnfV3-6b7B"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle='true')\n",
        "number_of_train = X_train.shape[0]\n",
        "number_of_test = X_test.shape[0]\n",
        "print('number_of_train:', number_of_train)\n",
        "print('number_of_test:', number_of_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnFqcgeY75ES"
      },
      "source": [
        "##ENSEMBLE LEARNING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiSEyKH279fW"
      },
      "source": [
        "###VGG16 CNN ARCHITECTURE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10MX1O2z8Fdw"
      },
      "source": [
        "early_stop=EarlyStopping(patience=4)\n",
        "reduceLR=ReduceLROnPlateau(patience=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrvsFdK98IAl"
      },
      "source": [
        "# detect and init the TPU\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "# instantiate a distribution strategy\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWQVUrHo8KxL"
      },
      "source": [
        "with tpu_strategy.scope():\n",
        "      vgg_model = VGG16(weights='imagenet',include_top=False)\n",
        "      for layers in vgg_model.layers:\n",
        "          layers.trainable=False\n",
        "      x=vgg_model.output\n",
        "      x=GlobalAveragePooling2D()(x)\n",
        "      x=Dense(128,activation='relu')(x)\n",
        "      x=Dropout(0.15)(x)\n",
        "      output=Dense(4,activation='softmax')(x)\n",
        "      model2=Model(inputs=vgg_model.input,outputs=output)\n",
        "      model2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEmBkEUY8POR"
      },
      "source": [
        "from random import shuffle\n",
        "\n",
        "ind_list = [i for i in range(len(X_train))]\n",
        "shuffle(ind_list)\n",
        "X_train_new  = X_train[ind_list, :,:,:]\n",
        "Y_train_new = Y_train[ind_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNctEtFu8Rd5"
      },
      "source": [
        "# Checkpoint to save best model per epoch\n",
        "model_filepath = \"/content/drive/My Drive/vgg-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
        "model_checkpoint_callbackvgg = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_filepath,\n",
        "    verbose=1,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLlrnRG-8U33"
      },
      "source": [
        "r2=model2.fit(X_train_new,Y_train_new,validation_split=0.2,epochs=20, callbacks=[model_checkpoint_callbackvgg])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6HktnMe8V9n"
      },
      "source": [
        "###ResNet50 CNN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eShQnRWf8da7"
      },
      "source": [
        "with tpu_strategy.scope():\n",
        "  res=tf.keras.applications.ResNet50(weights='imagenet',include_top=False)\n",
        "  for layers in res.layers:\n",
        "          layers.trainable=False\n",
        "  x=res.output\n",
        "  x=GlobalAveragePooling2D()(x)\n",
        "  x=Dense(128,activation='relu')(x)\n",
        "  x=Dropout(0.15)(x)\n",
        "  output=Dense(4,activation='softmax')(x)\n",
        "  model3=Model(inputs=res.input,outputs=output)\n",
        "  model3.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uybd-UxF8gBo"
      },
      "source": [
        "from random import shuffle\n",
        "\n",
        "ind_list = [i for i in range(len(X_train))]\n",
        "shuffle(ind_list)\n",
        "X_train_new  = X_train[ind_list, :,:,:]\n",
        "Y_train_new = Y_train[ind_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxFDbVFF8jQh"
      },
      "source": [
        "model_filepath = \"/content/drive/My Drive/res-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
        "model_checkpoint_callbackres = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_filepath,\n",
        "    verbose=1,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlOUlC4Y8lr9"
      },
      "source": [
        "r2=model3.fit(X_train_new,Y_train_new,validation_split=0.2,epochs=20, callbacks=[model_checkpoint_callbackres])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG6-lRxR8xgJ"
      },
      "source": [
        "###STACKED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1V8Xa_l8zuf"
      },
      "source": [
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Average\n",
        "model_1 = load_model(\"/content/drive/My Drive/vgg-13-0.7344.hdf5\")\n",
        "model_1 = Model(inputs=model_1.inputs,\n",
        "                outputs=model_1.outputs,\n",
        "                name='vgg16')\n",
        "model_2 = load_model(\"/content/drive/My Drive/res-20-0.8281.hdf5\")\n",
        "model_2 = Model(inputs=model_2.inputs,\n",
        "                outputs=model_2.outputs,\n",
        "                name='resnet50')\n",
        "models = [model_1, model_2]\n",
        "model_input = Input(shape=(image_width, image_height, 3))\n",
        "model_outputs = [model(model_input) for model in models]\n",
        "ensemble_output = Average()(model_outputs)\n",
        "ensemble_model = Model(inputs=model_input, outputs=ensemble_output, name='ensemble')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jndv_2Rn83bc"
      },
      "source": [
        "ensemble_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va2o8ajC85gW"
      },
      "source": [
        "model_filepath = \"/content/drive/My Drive/e1-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
        "model_checkpoint_callbacke1 = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=model_filepath,\n",
        "    verbose=1,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXKOe9uy873_"
      },
      "source": [
        "r4=ensemble_model.fit(X_train_new,Y_train_new,validation_split=0.2,epochs=20, callbacks=[model_checkpoint_callbacke1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}